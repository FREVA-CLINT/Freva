#!/bin/bash

# SET FREVA ROOT DIR via STRUCTURE
# This script (www_ingest) is belonging to the sbin
# It takes the old roles of crawl (find datasets) 
# and ingest (put information into the solr server)
#################

DATA_DIR=$1
SCRIPT_PATH=$(dirname $0)

FREVA_ROOT=$SCRIPT_PATH/../
SOLR_INGEST=$FREVA_ROOT/sbin/solr_ingest
SOLR_ROOT=$FREVA_ROOT/database/solr/

SERVER_DIR=$SOLR_ROOT/server/
INCOMING_DIR=$SOLR_ROOT/incoming/
PROCESSING_DIR=$SOLR_ROOT/processing/
BACKUP_DIR=$SOLR_ROOT/backup/

SOLR_HOME=$SERVER_DIR/mysolr/

####
# LOAD MODULES
module load evaluation_system 1>/dev/null 2>/dev/null
#######

###############
#setup evaluation system path
##########
export PYTHONPATH=$PYTHONPATH:$FREVA_ROOT/src
export PYTHON_EGG_CACHE=/tmp
#############

#############
# CRAWL PART
file=$(date +solr_crawl_%F_%H%M%S.csv.gz)
INCOMING_FILE=$INCOMING_DIR/$file


if [[ ! -d "$DATA_DIR" ]]; then
    echo "Directory '$DATA_DIR' doesn't exists. Aborting."
    exit 1
fi

#create file (gzipped to something of about 10Mb)
$SOLR_INGEST --crawl $DATA_DIR --output $INCOMING_FILE || exit 1

###############

############
# INGEST PART
log_file=$BACKUP_DIR/$file.log
exec > >(tee $log_file)
exec 2>&1
#move it away from incoming dir, to mark this thread as the one processing it
PROCESSING_FILE=$PROCESSING_DIR/$file
mv $INCOMING_FILE $PROCESSING_FILE || continue #if we can't we assume the file is not there anymore.
#ingest file
if $FREVA_ROOT/sbin/solr_ingest --ingest "$PROCESSING_FILE"; then
    echo "success"
    mv $PROCESSING_FILE $BACKUP_DIR/$file
else
    echo "FAILURE!"
    mv $PROCESSING_FILE $BACKUP_DIR/failed_$file
fi
##############
