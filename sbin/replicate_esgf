#!/usr/bin/env python
# encoding: utf-8
'''
esgf -- query the esgf search api

@copyright:  2012 FU Berlin. All rights reserved.
        
@contact:    estanislao.gonzalez@met.fu-berlin.de

@license:    BSD

Copyright (c) 2012, FU Berlin
All rights reserved.

Redistribution and use in source and binary forms, with or without modification,
 are permitted provided that the following conditions are met:

    Redistributions of source code must retain the above copyright notice, this 
    list of conditions and the following disclaimer.
    Redistributions in binary form must reproduce the above copyright notice, 
    this list of conditions and the following disclaimer in the documentation 
    and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, 
INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, 
BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, 
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY 
OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE 
OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED 
OF THE POSSIBILITY OF SUCH DAMAGE.
'''

                                                                                                                                                                     
"""This file handles the preparation of scripts for the retrieval of data from ESGF"""
#get p2p.py: 
#  wget 'http://esgf.org/gitweb/?p=esgf-replication.git;a=blob_plain;f=replication/model/p2p.py;hb=HEAD' -O p2p.py
import sys

from evaluation_system.model.esgf import P2P


def get_wget_script(node='esgf-data.dkrz.de', output='wget.sh', **search):
    """Retrieves a dummy wget script used for parsing the list of files generated here"""
    from subprocess import call
    call(['wget', 'http://%s/esg-search/wget?distrib=false&limit=1' % node, '-O', output])

def get_download_list(node='esgf-data.dkrz.de', output=sys.stdout, to_local=lambda no_change: no_change, **search):
    """Generates a list of files as requested from the search parameters"""
    p = P2P(node=node)

    if isinstance(output, basestring):
        output = open(output, 'w')

    for f in p.files(fields='url,checksum', **search):
        url = [url.split('|')[0] for url in f['url'] if url.split('|')[2] == 'HTTPServer'][0]
        try:
            output.write("'%s' '%s' 'MD5' '%s'\n" % (to_local(url), url, f['checksum'][0]))
            output.flush()
        except:
            sys.exit(1)

    if output != sys.stdout: output.close()

def get_md5_list(node='esgf-data.dkrz.de', output=sys.stdout, to_local=lambda no_change: no_change, **search):
    """Generates a list of files as requested from the search parameters"""
    p = P2P(node=node)

    if isinstance(output, basestring):
        output = open(output, 'w')

    for f in p.files(fields='url,checksum', **search):
        url = [url.split('|')[0] for url in f['url'] if url.split('|')[2] == 'HTTPServer'][0]
        try:
            output.write("%s  %s\n" % (f['checksum'][0], to_local(url)))
            output.flush()
        except:
            sys.exit(1)

    if output != sys.stdout: output.close()

def get_technotes(node='esgf-data.dkrz.de', output=sys.stdout, **search):
    """Generates a list of files as requested from the search parameters"""
    p = P2P(node=node)

    if isinstance(output, basestring):
        output = open(output, 'w')

    seen = set()
    for f in p.files(fields='xlink', query='xlink:*', **search):
        for url in [url.split('|')[0] for url in f['xlink']]:
            if url in seen: continue
            seen.add(url)
            try:
                output.write(url + '\n')
                output.flush()
            except:
                sys.exit(1)

    if output != sys.stdout: output.close()

def get_facets(facets, node='esgf-data.dkrz.de', output=sys.stdout, **search):
    p = P2P(node=node)

    if isinstance(output, basestring):
        output = open(output, 'w')

    for facet, values in sorted(p.get_facets(*facets, **search).items()):
        for value, count in sorted(values.items()):
            try:
                output.write('%s\t%s\t%s\n' % (facet, value, count))
                output.flush()
            except:
                sys.exit(1)

    if output != sys.stdout: output.close()

def list_facets(node='esgf-data.dkrz.de', output=sys.stdout, **search):
    p = P2P(node=node)

    if isinstance(output, basestring):
        output = open(output, 'w')
    #some defaults:
    if 'distrib' not in search: search['distrib'] = False

    for facet in sorted(p.get_facets('*', **search)):
        try:
            output.write('%s\n' % (facet))
            output.flush()
        except:
            sys.exit(1)

    if output != sys.stdout: output.close()

def count_files(node='esgf-data.dkrz.de',  **search):
    p = P2P(node=node)
    tot_files = 0
    tot_size = 0
    for dataset in p.get_datasets(fields='number_of_files,size', **search):
        tot_files += dataset['number_of_files']
        tot_size += dataset['size']

    print 'Total number of files: %s\nTotal Size: %.3fGb' % (tot_files, tot_size/1024.0/1024.0/1024.0)

#**** COMMAND LINE ****
def auto_doc(message=''):
    """Just output help automatically from the parser in here"""
    import re, os
    f = sys.argv[0]
    script_name = os.path.basename(f)

    re_start = re.compile('.*\*!!!\*$')
    re_end = re.compile('^[ \t]*$')
    re_entries= re.compile("^[^']*'([^']*)'[^']*(?:'([^']*)')?[^#]*#(.*)$")
    parsing=False
    results = []
    for line in open(f, 'r'):
        if parsing:
            items = re_entries.match(line)
            if items:
                flag, flag_opt, mesg = items.groups()
                if flag_opt: flag = '%s, %s' % (flag, flag_opt)
                results.append('  %-20s : %s' % (flag, mesg))
            if re_end.match(line): break
        elif re_start.match(line): parsing = True

    if results: print '%s%s [opt]\nopt:\n%s' % (message, script_name, '\n'.join(results))
    else: print '%s %s' % (os.path.basename(f), message)

def show_examples():
    #show some examples
    import os
    script_name = os.path.basename(sys.argv[0])
    print """
Examples:
    $ %s --list-facets

Show a list of all available facets a t the local index (defaults to esgf-data.dkrz.de)


    $ %s -f project=CMIP5 --facet-count institute

Displays a list of Institutes and the amount of dataset they have published for the CMIP5 project.


    $ %s --facet-count index_node experiment=MERRA

Displays a list of index_nodes where the data for the MERRA experiment is hosted. The search arguments might be also put at the end
of the command, in such case you don't need to set the flag -f again.

    $ %s -f project_not_=CMIP5 -f query=experiment:decadal* --facet-count institute

Display a list of institutes and the amount of dataset they have published to the decadal experiments (note Lucene query syntax) from all projects *EXCLUDING* CMIP5 (note the negation coded as <key>_not_=<value>).


    $ %s -f 'dataset_id=cmip5.output1.MPI-M.MPI-ESM-LR.1pctCO2.day.atmos.cfDay.r1i1p1.v20120314|bmbf-ipcc-ar5.dkrz.de' -f distrib=false -f variable=zg

Search locally at esgf-data.dkrz.de (default) for all files containing the zg variable 
from a given dataset (note the dataset *must* be versioned and it's datanode defined. 
The output will be sent to the standard out.


    $ %s -f project=obs4MIPs -f time_frequency=mon -o results.list --regex-dir 'https?://.*/observations/=/data/observations/' --regex-dir 'https?://.*/obs4MIPs[^/]*/=/data/observations/' --node esg-datanode.jpl.nasa.gov

Perform a federated search starting from esg-datanode.jpl.nasa.gov index node for all 
files from project 'obs4MIPs' with a monthly time resolution storing them in results.lists 
and replacing all urls up to the '../observations/' path part with '/data/observations/' 
if that doesn't apply (i.e. there's no 'observations' in the path) then replace the url 
up to the 'obs4MIPs.*' path element with '/data/observations/'.


    $ %s -f 'query=dataset_id:*bmbf-ipcc-ar5.dkrz.de' -f distrib=false -f limit=3

This shows the use of the query facet allowing to use any Lucene (Solr) query. Here it 
just get's 3 files (randomly) from the data node.

For more advanced information refer to the Search API
http://esgf.org/wiki/ESGF_Search_API

""" % tuple([script_name] * 7)

def usage(message=None):
    if message: auto_doc(message)
    else: auto_doc()

def main(argv=None):
    import getopt
    import re
    facet_pat = re.compile(r'(.*[^\\])=(.*)')

    if argv is None: argv = sys.argv[1:]
    try:
        args, lastargs = getopt.getopt(argv, "f:o:h", ['help','facet=','wget-dummy',
                        'regex-dir=', 'node=', 'technotes', 'examples', 'facet-count=',
                        'list-facets', 'count-files', 'md5-list'])
    except getopt.error:
        print "We couldn't parse the option list. Verify it is correct and try again"
        print "(Use -h to see the list of available options)"
        return 1

    #We need some argument always!
    if not (args or lastargs):
        usage('Please provide the required flags or arguments.\n')
        return 0


    #some initialization
    search_query = {}
    output=None
    to_local=None
    node=None
    technotes=False
    md5_list = False
    wget_script = False
    count=False
    regex_path = []
    facets= []
    _list_facets = False

    #parse arguments *!!!*
    for flag, arg in args:
        if flag=='-f' or flag=='--facet':       # Set facet for search (e.g. institute=MPI) can be used multiple times.
            try:
                facet, value = facet_pat.match(arg).groups()
                if facet in search_query:
                    #accept same value multiple times!
                    if not isinstance(search_query[facet], list): search_query[facet] = [search_query[facet]]
                    search_query[facet].append(value)
                else:
                    search_query[facet] = value
            except:
                print "Wrong facet syntax. Assure it is <key>=<value> (e.g. project=CMIP5)"
                return 1
        elif flag=='--wget-dummy':              # Generates a dummy wget script
            wget_script = True
        elif flag=='-o':                        # Store output to the given file
            output=arg
        elif flag=='--node':                    #<node> Use this specific index node instead of esgf-data.dkrz.de
            node=arg
        elif flag=='--technotes':               # Get a list of technotes
            technotes=True
        elif flag=='--list-facets':             # List all available facets (defaults to distrib=False, use -f distrib=True to change)
            _list_facets = True
        elif flag=='--count-files':             # Count the nu,mber of files and the size of the selection.
            count = True
        elif flag=='--facet-count':             # Get the values and their count for a given facet. Can be defined multiple times.
            facets.append(arg)
        elif flag=='--md5-list':                # Get a list of values that can be used with md5sum to check what was changed
            md5_list = True
        elif flag=='--regex-dir':               #<regex>=<target> Remap url to target, e.g. --regex-dir 'https://.*/obs4MIPs/=/my_path/obs4MIPs/' Can be used multiple times.
            source, target = arg.split('=')
            regex_path.append((re.compile(source), target))
        elif flag=='--examples':                # Show some examples
            show_examples()
            return 0
        elif flag=='-h' or flag=='--help':      # This help
            usage('Create scripts and download lists for downloading data from ESGF\n')
            return 0
    for arg in lastargs:
        try:
            facet, value = facet_pat.match(arg).groups()
            if facet in search_query:
                #accept same value multiple times!
                if not isinstance(search_query[facet], list): search_query[facet] = [search_query[facet]]
                search_query[facet].append(value)
            else:
                search_query[facet] = value
        except:
            print "Wrong facet syntax. Assure it is <key>=<value> (e.g. project=CMIP5)"
            return 1


    #check and prepare regex if defined
    if regex_path:
        def _to_local(url):
            for reg_pat, target in regex_path:
                #if no match, sub returns the same string
                new_path = reg_pat.sub(target, url)
                #so if different return it, if not keep trying (== is as fast as 'is')
                if new_path != url: return new_path
            return url
        to_local = _to_local


    if output and output != '-': search_query['output'] = output
    if to_local: search_query['to_local'] = to_local
    if node: search_query['node'] = node
    if technotes:
        get_technotes(**search_query)
    elif wget_script:
        get_wget_script(**search_query)
    elif _list_facets:
        list_facets(**search_query)
    elif facets:
        get_facets(facets, **search_query)
    elif count:
        count_files(**search_query)
    elif md5_list:
        get_md5_list(**search_query)
    else:
        get_download_list(**search_query)

if __name__ == '__main__':
    main()
