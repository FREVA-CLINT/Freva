#!/usr/bin/env python
# encoding: utf-8

'''
crawl_my_data - Sets path to crawl a useres data

@copyright:  2015 FU Berlin. All rights reserved.
        
@contact:    sebastian.illing@met.fu-berlin.de

@license:    BSD

Copyright (c) 2015, FU Berlin
All rights reserved.

Redistribution and use in source and binary forms, with or without modification,
 are permitted provided that the following conditions are met:

    Redistributions of source code must retain the above copyright notice, this 
    list of conditions and the following disclaimer.
    Redistributions in binary form must reproduce the above copyright notice, 
    this list of conditions and the following disclaimer in the documentation 
    and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND 
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED 
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. 
IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, 
INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, 
BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, 
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY 
OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE 
OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED 
OF THE POSSIBILITY OF SUCH DAMAGE.
'''

import sys, os, time
from evaluation_system.commands import BaseCommand
from evaluation_system.model.user import User
import logging
from evaluation_system.model.solr_models.models import UserCrawl

class UpdateProjectdata(BaseCommand):
 
    _short_args = 'hd'
    _args = ['path=', 'debug', 'help']
    __short_description__ = '''\nUse this command to update your projectdata.'''
    
    def _run(self):
        #TODO: This should be in evaluation_system.conf
        root_path = '/miklip/integration/data4miklip/projectdata/'
        # Setup argument parser
        args = self.args
        crawl_dir=None
        
	t1 = time.time()        
        #parse arguments *!!!*
        for flag, arg in args:
            if flag == '--path':                 #crawl the given directory
                crawl_dir=arg
        #flush stderr in case we have something pending
        sys.stderr.flush()
        user_root_path = os.path.join(root_path,User().getName()) 
        if crawl_dir:
            if(not root_path in crawl_dir):
                raise Exception('You are only allowed to crawl data in this root path %s' % root_path)
        else:
            crawl_dir = user_root_path
        user=User()
        db = user.getUserDB()
        crawl_id = db.create_user_crawl(crawl_dir,user.getName())
	print 'Please wait while the system is crawling your data'
	printed_msg = []
	while True:
	    time.sleep(5)
	    crawl = UserCrawl.objects.get(id=crawl_id)
	    for line in crawl.ingest_msg.split('\n'):
	        if line not in printed_msg:
	            print line
		    printed_msg.append(line)
	    if crawl.status == 'success' or crawl.status == 'failed':
                break
	if crawl.status == 'success':
            print 'Finished.\nCrawling took ' + str(time.time() - t1) + ' seconds'


if __name__ == "__main__":
    inst = UpdateProjectdata()
    inst.run()
